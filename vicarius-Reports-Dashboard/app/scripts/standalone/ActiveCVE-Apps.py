import time
import pandas as pd
import requests
import json
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta

apikey = "" #https://customer-portal.vicarius.io/getting-started-with-vrx-rest-api
urldashboard = "" # https://<Dashboard Name>.vicarius.cloud 



DEFAULT_QUERY_LIMIT_PER_MINUTE = 55

def control_rate(query_limit=None):
    global last_query_time

        # Use the default rate limit if none is provided
    if query_limit is None:
        query_limit = DEFAULT_QUERY_LIMIT_PER_MINUTE

    # Calculate the time since the last query
    elapsed_time = time.time() - last_query_time

    # If less than a minute has passed since the last query, wait
    if elapsed_time < 60:
        # Calculate the time to sleep based on the desired rate
        sleep_time = max(0, (60 / query_limit) - elapsed_time)
        time.sleep(sleep_time)

    # Update the last query time
    last_query_time = time.time()

# APPS HasPatch and Risk Score DF/LIST
def getallAppwithPatch(apikey,urldashboard):
    headers = {
      'Content-Type': 'application/json',
      'Vicarius-Token': apikey,
      'Cookie': 'Vicarius-Token=' + apikey
    }
    params = {
        'from': 0,
        'size': 10,
        'objectName': 'OrganizationPublisherProducts',
        'group': 'organizationPublisherProductsOrganizationPublisherProductsScores.organizationPublisherProductsScoresSensitivityLevel.sensitivityLevelName',
        'includeOriginalDoc': 'false',
    }
    
    payload = json.dumps([
      {
        "searchQueryName": "appPatch",
        "searchQueryObjectName": "OrganizationEndpointPublisherProductHashtags",
        "searchQueryObjectJoinByFieldName": "publisherProductHash",
        "searchQueryObjectJoinByForeignFieldName": "publisherProductHash",
        "searchQueryQuery": "organizationEndpointPublisherProductHashtagsHashtag.hashtagTag=in=(#has_patch)",
        "searchQueryQueryJoinType": ""
      }
    ])
    url = '/vicarius-external-data-api/aggregation/searchGroup?'
    response = requests.request("GET",urldashboard + url, params=params, headers=headers, data=payload)
    jsonresponse = json.loads(response.text)
    #print(jsonresponse)
    sro = jsonresponse['serverResponseObject']
    #print(sro)
    for i in sro:
        if "Low" in i['aggregationId']:
            lowRiskApps = i['aggregationCount']
            #print(lowRiskApps)
        if "Medium" in i['aggregationId']:
            mediumRiskApps = i['aggregationCount']
            #print(mediumRiskApps)
        if "High" in i['aggregationId']:
            highRiskApps = i['aggregationCount']
            #print(highRiskApps)
    return lowRiskApps,mediumRiskApps,highRiskApps
    
def getAppswithRiskandPatch(apikey,urldashboard,riskLevel,fr0m,siz3):

    url = urldashboard + "/vicarius-external-data-api/organizationPublisherProducts/search?from=" + str(fr0m) + "&size=" + str(siz3) + "&sort=-organizationPublisherProductsOrganizationPublisherProductsScores.organizationPublisherProductsScoresScore%3BpublisherProductHash&q=&includeFields=publisherProductHash%2CorganizationPublisherProductsUpdatedAt%2CorganizationPublisherProductsProduct.productName%2CorganizationPublisherProductsProduct.productId%2CorganizationPublisherProductsProduct.productUniqueIdentifier%2CorganizationPublisherProductsPublisher.publisherName%2CorganizationPublisherProductsPublisher.publisherId%2CorganizationPublisherProductsPhoto.photoId%2CorganizationPublisherProductsOrganizationPublisherProductsScores.organizationPublisherProductsScoresScore%2CorganizationPublisherProductsOrganizationPublisherProductsScores.organizationPublisherProductsScoresImpactRiskFactors%2CorganizationPublisherProductsOrganizationPublisherProductsScores.organizationPublisherProductsScoresExploitabilityRiskFactors%2CorganizationPublisherProductsOrganizationPublisherProductsScores.organizationPublisherProductsScoresSensitivityLevel.sensitivityLevelName"

    payload = json.dumps([
      {
        "searchQueryName": "apps",
        "searchQueryObjectName": "OrganizationPublisherProducts",
        "searchQueryObjectJoinByFieldName": "publisherProductHash",
        "searchQueryObjectJoinByForeignFieldName": "publisherProductHash",
        "searchQueryQuery": "organizationPublisherProductsOrganizationPublisherProductsScores.organizationPublisherProductsScoresSensitivityLevel.sensitivityLevelName=in=(" + riskLevel +")",
        "searchQueryQueryJoinType": ""
      },
      {
        "searchQueryName": "appPatch",
        "searchQueryObjectName": "OrganizationEndpointPublisherProductHashtags",
        "searchQueryObjectJoinByFieldName": "publisherProductHash",
        "searchQueryObjectJoinByForeignFieldName": "publisherProductHash",
        "searchQueryQuery": "organizationEndpointPublisherProductHashtagsHashtag.hashtagTag=in=(#has_patch)",
        "searchQueryQueryJoinType": ""
      }
    ])
    headers = {
      'Content-Type': 'application/json',
      'Vicarius-Token': apikey,
      'Cookie': 'Vicarius-Token=' + apikey
    }

    response = requests.request("GET", url, headers=headers, data=payload)

    #print(response.text)
    jsonresponse = json.loads(response.text)
    sro = jsonresponse['serverResponseObject']
    appObj = []
    #print(sro)
    for i in sro:
        publisherHash = i['publisherProductHash']
        productId = i['organizationPublisherProductsProduct']['productId']
        productName = i['organizationPublisherProductsProduct']['productName']
        appRiskLevel = i['organizationPublisherProductsOrganizationPublisherProductsScores']['organizationPublisherProductsScoresSensitivityLevel']['sensitivityLevelName']
        appRiskScore = i['organizationPublisherProductsOrganizationPublisherProductsScores']['organizationPublisherProductsScoresScore']
        productUpdatedAt = i['organizationPublisherProductsUpdatedAt']
        productUpdatedAt =  datetime.fromtimestamp(productUpdatedAt / 1000).isoformat()
        VulnerabilityCVSS = ""
        predictedAttackSurface = ""
        hasPatch = ""
        vulExploit = ""
        for imr in i['organizationPublisherProductsOrganizationPublisherProductsScores']['organizationPublisherProductsScoresImpactRiskFactors']:
            if "HighVulnerabilityCVSS" in imr['riskFactorTerm']:
                VulnerabilityCVSS = imr['riskFactorTerm']
            if "HighPredictedAttackSurface" in imr['riskFactorTerm']:
                predictedAttackSurface = imr['riskFactorTerm']
        for imr in i['organizationPublisherProductsOrganizationPublisherProductsScores']['organizationPublisherProductsScoresExploitabilityRiskFactors']:
            if "#has_patch" in imr['riskFactorDescription']:
                hasPatch = imr['riskFactorDescription']
            if "#new_vulnerability_published" in imr['riskFactorDescription']:
                vulExploit = imr['riskFactorDescription']
        appjson = {
            "appName": productName,
            "productID": productId,
            "publisherHash": publisherHash,
            "riskLevel": appRiskLevel,
            "riskScore": appRiskScore,
            "vulRiskFactor": VulnerabilityCVSS,
            "predictedAttackSurface": predictedAttackSurface,
            "patch": hasPatch,
            "vulExploit": vulExploit,
            "ProductUpdatedAt": productUpdatedAt
        }
        appObj.append(appjson)
    return appObj

def getAppsPerRisk(fr0m,siz3):
    #db.check_create_table_apps(host, port, user, password, database)
    #db.clean_table_apps(host, port, user, password, database)

    lowRiskAppsCount,mediumRiskAppsCount,highRiskAppsCount = getallAppwithPatch(apikey,urldashboard)
    lrac = lowRiskAppsCount
    mrac = mediumRiskAppsCount
    hrac = highRiskAppsCount
    #print(lowRiskAppsCount,mediumRiskAppsCount,highRiskAppsCount)
    print("Apps with #has_patch ->")
    # Sort counts
    appsList = [] 
    fr0m = 0
    #LOW RISK APPS 
    while lowRiskAppsCount > 500:
        siz3 = 500
        lowriskApps = getAppswithRiskandPatch(apikey,urldashboard,"Low",fr0m,siz3)
        for row in lowriskApps:
            appsList.append(row)       
        print("500 Low Risk Apps Inserted")
        lowRiskAppsCount = lowRiskAppsCount - siz3
        fr0m += siz3
    siz3 = lowRiskAppsCount
    lowriskApps = getAppswithRiskandPatch(apikey,urldashboard,"Low",fr0m,siz3)
    for row in lowriskApps:
        appsList.append(row)
    print(str(lowRiskAppsCount) + " Low Risk Apps Inserted")
    
    fr0m = 0
    #MEDIUM RISK APPS
    while mediumRiskAppsCount > 500:
        siz3 = 500
        medriskApps = getAppswithRiskandPatch(apikey,urldashboard,"Medium",fr0m,siz3)
        print("500 Medium Risk Apps Inserted")
        for row in medriskApps:
            appsList.append(row)
        mediumRiskAppsCount = mediumRiskAppsCount - siz3
        fr0m += siz3
    siz3 = mediumRiskAppsCount
    medriskApps = getAppswithRiskandPatch(apikey,urldashboard,"Medium",fr0m,siz3)
    for row in medriskApps:
        appsList.append(row)
    print(str(mediumRiskAppsCount) + " Medium Risk Apps Inserted")

    #HIGH RISK APPS
    fr0m = 0
    while highRiskAppsCount > 500:
        siz3 = 500
        highriskApps = getAppswithRiskandPatch(apikey,urldashboard,"High",fr0m,siz3)
        for row in highriskApps:
            appsList.append(row)
        print("500 High Risk Apps Inserted")
        highRiskAppsCount = highRiskAppsCount - siz3
        fr0m += siz3
    siz3 = highRiskAppsCount
    highriskApps = getAppswithRiskandPatch(apikey,urldashboard,"High",fr0m,siz3)
    for row in highriskApps:
        appsList.append(row)
    print(str(highRiskAppsCount) + " High Risk Apps Inserted")

    totalAC = lrac + mrac + hrac
    print (str(totalAC) + " Apps inserted")

    appsDF = pd.DataFrame(appsList)
    return appsDF,appsList

#CVE Active Vulns Report 
def get_days_diff_from_timestamp(timestamp_ms):
    # Converter timestamp em milissegundos para objeto datetime
    dt = datetime.datetime.fromtimestamp(timestamp_ms / 1000.0)

    # Obter a data atual
    current_date = datetime.datetime.now().date()

    # Calcular a diferença em dias entre as duas datas
    diff = current_date - dt.date()

    # Retornar a diferença em dias
    return diff.days

def getCountEvents(apikey,urldashboard,lastdate):
    headers = {
        'Accept': 'application/json',
        'Vicarius-Token': apikey,
    }
    
    params = {
        'from': 0,
        'size': 1,
        'q' : 'organizationEndpointVulnerabilitiesEndpoint.endpointCreatedAt>' + str(lastdate)
    }
    response = requests.get(urldashboard + '/vicarius-external-data-api/organizationEndpointVulnerabilities/search', params=params, headers=headers)

    jsonresponse = json.loads(response.text)
        
    responsecount = jsonresponse['serverResponseCount']

    return responsecount
    
def getEndpointVulnerabilities(apikey,urldashboard,fr0m,siz3,minDate,maxDate,endpointName,endpointHash):

    headers = {
        'Accept': 'application/json',
        'Vicarius-Token': apikey,
    }

    params = {
        'from': fr0m,
        'size': siz3,
        'q': 'organizationEndpointVulnerabilitiesCreatedAt>'+str(minDate)+';organizationEndpointVulnerabilitiesCreatedAt<'+str(maxDate)+';organizationEndpointVulnerabilitiesEndpoint.endpointHash=in=('+endpointHash+')', #.endpointName==' + endpointName,
        'sort' : '-organizationEndpointVulnerabilitiesCreatedAt',
    }
    jresponse = []
    try:
        time.sleep(0.5)
        response = requests.get(urldashboard + '/vicarius-external-data-api/organizationEndpointVulnerabilities/search', params=params, headers=headers)
        jresponse = json.loads(response.text)
  
    except:
        print("something is wrong, will try again....")
        time.sleep(30)
        getEndpointVulnerabilities(apikey,urldashboard,fr0m,siz3,minDate,maxDate,endpointName,endpointHash)

    return jresponse

def parseEndpointVulnerabilities(apikey,urldashboard,jresponse): #endpointGroups):
    
    vulns_list = []


    for i in jresponse['serverResponseObject']:
        cve = i['organizationEndpointVulnerabilitiesVulnerability']['vulnerabilityExternalReference']['externalReferenceExternalId']
        vulid = str(i['organizationEndpointVulnerabilitiesVulnerability']['vulnerabilityId'])
        link = "https://www.vicarius.io/vsociety/vulnerabilities/"+vulid+"/"+cve
        #'https://www.vicarius.io/research-center/vulnerability/'+ cve + '-id' + vulid
        
        typecve = ""

        try:
            productName = i['organizationEndpointVulnerabilitiesProduct']['productName']
            typecve = "App"
        except:
            productName = ""

        try:
            productName = i['organizationEndpointVulnerabilitiesOperatingSystem']['operatingSystemName']
            typecve = "SO"
        except:
            if (typecve != "App"):
                productName = ""

        try:
            version = i['organizationEndpointVulnerabilitiesVersion']['versionName']
        except:
            version = ""
        try:
            subVersion = i['organizationEndpointVulnerabilitiesSubVersion']['subVersionName']
        except:
            subVersion = productRawEntryName

        productRawEntryName = i['organizationEndpointVulnerabilitiesProductRawEntry']['productRawEntryName']
        sensitivityLevelName = i['organizationEndpointVulnerabilitiesVulnerability']['vulnerabilitySensitivityLevel']['sensitivityLevelName']
        
        vulnerabilitySummary = i['organizationEndpointVulnerabilitiesVulnerability']['vulnerabilitySummary'] 
        vulnerabilitySummary = str(vulnerabilitySummary).replace("\"","'")
        
        asset = i['organizationEndpointVulnerabilitiesEndpoint']['endpointName']
        endpointId = (i['organizationEndpointVulnerabilitiesEndpoint']['endpointId'])
        endpointHash = i['organizationEndpointVulnerabilitiesEndpoint']['endpointHash']

        if i['organizationEndpointVulnerabilitiesPatch']['patchId'] > 0:
            patchid = str(i['organizationEndpointVulnerabilitiesPatch']['patchId'])
            patchName = (i['organizationEndpointVulnerabilitiesPatch']['patchName'])
            patchReleaseDate = i['organizationEndpointVulnerabilitiesPatch']['patchReleaseDate']
            #patchFileName = str(i['organizationEndpointVulnerabilitiesPatch']['patchFileName'])
        else:
            patchid = "0"
            patchName = "n\\a"
            patchReleaseDate = 0000000000000
            #patchFileName = "n\\a"

        try:
            createAttimemille = i['organizationEndpointVulnerabilitiesCreatedAt']
            createAt = utils.timestamptodatetime(createAttimemille)
            updateAt = i['organizationEndpointVulnerabilitiesUpdatedAt']
            updateAt = utils.timestamptodatetime(updateAt)
        except:
            createAt = ""
            updateAt = ""

        productName = productName.replace(',',"").replace(";","")
        productRawEntryName = productRawEntryName.replace(',',"").replace(";","")
        vulnerabilitySummary = vulnerabilitySummary.replace("\r","").replace("\n",">>")
        vulnerabilitySummary = vulnerabilitySummary.replace(",","").replace(";","")
        vulnerabilitySummary = vulnerabilitySummary.replace("'","")
        
        #threatLevelId = str(i['organizationEndpointVulnerabilitiesVulnerability']['vulnerabilitySensitivityLevel']['threatLevelId'])
        vulnerabilityV3ExploitabilityLevel = str(i['organizationEndpointVulnerabilitiesVulnerability']['vulnerabilityV3ExploitabilityLevel'])
        vulnerabilityV3BaseScore = str(i['organizationEndpointVulnerabilitiesVulnerability']['vulnerabilityV3BaseScore'])
    
        if patchReleaseDate < 1:
            patchReleaseDate = createAttimemille
            patchReleaseDate = patchReleaseDate / 1000
        hpatchReleaseDate = datetime.fromtimestamp(int(patchReleaseDate) / 1000).isoformat()


        #age = get_days_diff_from_timestamp(createAttimemille)

        vulnerability_dict = {
            "endpointId" : endpointId,
            "asset": asset,
            "endpointHash": endpointHash,
            "productName": productName,
            "productRawEntryName": productRawEntryName,
            "sensitivityLevelName": sensitivityLevelName,
            "cve": cve,
            "vulid": vulid,
            "patchid": patchid,
            "patchName": patchName,
            "patchReleaseDate": patchReleaseDate,
            "patchReleaseDateTimeStamp": hpatchReleaseDate,
            "createAt": createAt,
            "updateAt": updateAt,
            "link": link,
            "vulnerabilitySummary": vulnerabilitySummary,
            "vulnerabilityV3BaseScore": vulnerabilityV3BaseScore,
            "vulnerabilityV3ExploitabilityLevel": vulnerabilityV3ExploitabilityLevel,
            "typecve": typecve,
            "version": version,
            "subversion": subVersion
        }

        vulns_list.append(vulnerability_dict)

        #add json return for vulnerabilties
        #strVulnerabilities += ("'" + asset + "','" + endpointHash + "','" + productName + "','" + productRawEntryName + "','" + sensitivityLevelName + "','" + cve + "'," + vulid + "," + patchid + ",'" + patchName + "'," + patchReleaseDate + ",'" + createAt + "','" + updateAt + "','" + link + "','\"" + vulnerabilitySummary + "\"'," +vulnerabilityV3BaseScore + "," + vulnerabilityV3ExploitabilityLevel + ",'" + typecve + "','" + version + "'," + str(age) +"\n")

        maxDate = createAttimemille

    return vulns_list, maxDate

# ENDPOINTS REPORT 
def getCountEndpoints(apikey,urldashboard):

    headers = {
        'Accept': 'application/json',
        'Vicarius-Token': apikey,
    }

    params = {
        'from': 0,
        'size': 1,
    }

    try:
        response = requests.get(urldashboard + '/vicarius-external-data-api/endpoint/search', params=params, headers=headers)
        jsonresponse = json.loads(response.text)
        responsecount = jsonresponse['serverResponseCount']

    except:
        print("something is wrong, will try again....")

    return responsecount

def getEndpoints(apikey,urldashboard,fr0m,siz3):

    headers = {
        'Accept': 'application/json',
        'Vicarius-Token': apikey,
    }

    params = {
        'from': fr0m,
        'size': siz3,
    }

    try:
        response = requests.get(urldashboard + '/vicarius-external-data-api/endpoint/search', params=params, headers=headers)
        parsed = json.loads(response.text)        
        
    except:
        print("something is wrong, will try again....")

    strEndpoints = ""
    endpoints_list = []
    for i in parsed['serverResponseObject']:
        deployment_date = str(i['endpointCreatedAt'])
        last_connected = str((i['endpointUpdatedAt']))
        operatingSystemName = (i['endpointOperatingSystem']['operatingSystemName'])
        agentVersion = (i['endpointVersion']['versionName'])
        alive = (i['endpointAlive'])
        if alive == "true":
            now = datetime.now()
            LastContact = now.strftime('%Y-%m-%dT%H:%M:%S')
        else:
            LastContact = datetime.fromtimestamp(int(last_connected) / 1000).isoformat()
        tokenGenTimeUNX = (i['endpointTokenGenerationTime'])
        tokenGenTime = datetime.fromtimestamp(int(tokenGenTimeUNX) / 1000).isoformat()
        deploymentDateUNX = i['endpointCreatedAt']
        deploymentDate = datetime.fromtimestamp(int(deploymentDateUNX) / 1000).isoformat()
        try:
            substatus = i['endpointEndpointSubStatus']['endpointSubStatusName']
        except: 
            substatus = ""
        try: 
            connectedbyProxy = i['endpointConnectedByProxy']
        except:
            connectedbyProxy = ""
        endpoints_JSON = {
            "id": i['endpointId'],
            "hostname": i['endpointName'] ,
            "hash": i['endpointHash'],
            "alive": alive,
            "so": operatingSystemName,
            "version":agentVersion,
            "substatus":substatus,
            "connectedbyproxy": connectedbyProxy,
            "tokengentime": tokenGenTime,
            "deployed": deployment_date,
            "last_connected": last_connected,
            "deploymentdate": deploymentDate,
            "lastcontactdate": LastContact
        }
        endpoints_list.append(endpoints_JSON)
        strEndpoints += ("'" + str(i['endpointId']) + "','" + i['endpointName'] + "','" + i['endpointHash'] + "','" + str(alive) + "','" + operatingSystemName + "','" + agentVersion + "','" + substatus + "','" + str(connectedbyProxy) + "','" + tokenGenTime + "','" + deployment_date + "','" + last_connected + "','" + deploymentDate + "','" + LastContact + "'\n")
    
    return endpoints_list

#****************** Get Enpoints DF/LIST ******************
endpointcount = getCountEndpoints(apikey,urldashboard)
epCount = endpointcount
print("Endpoints -> " + str((endpointcount) ))
fr0m = 0
endpointsList = []
while endpointcount > 500:
    siz3 = 500
    strEndpoints = getEndpoints(apikey,urldashboard,fr0m,siz3)
    for row in strEndpoints:
        endpointsList.append(row)
    endpointcount = endpointcount - siz3
    fr0m += siz3

siz3 = endpointcount
strEndpoints = getEndpoints(apikey,urldashboard,fr0m,siz3)
for row in strEndpoints:
    endpointsList.append(row)

#print(endpointsList)
    
#****************** Get CVEs per Endpoint ******************
endpointsDF = pd.DataFrame(endpointsList)
endpointsDF = endpointsDF.sort_values(by='last_connected', ascending=False)
endpointsDF = endpointsDF.drop_duplicates(subset=['hostname'], keep='first')
#print("ENDPOINTS DF:")
#print(endpointsDF)
dateNow = datetime.now()
minDate = 0000000000000
maxDate = str(int(float(dateNow.timestamp())*1000))
fr0m = 0
siz3 = 500
allCVEList = []
acount = 0
for ind in endpointsDF.index:
    acount += 1
    endpointName = endpointsDF['hostname'][ind]
    endpointHash = endpointsDF['hash'][ind]
    print(str(acount) + "/" + str(epCount))
    jresponse = getEndpointVulnerabilities(apikey, urldashboard, fr0m, siz3, minDate, maxDate, endpointName, endpointHash)
    server_response_count = jresponse.get('serverResponseCount', 0)
    src = server_response_count
    if server_response_count > 0:
        strVulnerabilities, maxDate = parseEndpointVulnerabilities(apikey, urldashboard, jresponse)    
        for row in strVulnerabilities:
            allCVEList.append(row)
    src -= siz3
    while src > siz3:
        jresponse = getEndpointVulnerabilities(apikey, urldashboard, fr0m, siz3, minDate, maxDate, endpointName, endpointHash)
        server_response_count = jresponse.get('serverResponseCount', 0)
        src = server_response_count
        if server_response_count > 0:
            strVulnerabilities, maxDate = parseEndpointVulnerabilities(apikey, urldashboard, jresponse)
            for row in strVulnerabilities:
                allCVEList.append(row)
        src -= siz3
#print(allCVEList)
allCVEDF = pd.DataFrame(allCVEList)
#print(allCVEDF)
    

#Run Reports 02.

#Apps Report 
#****************** Get Apps with Has_Patch ******************
appsDF,appsList = getAppsPerRisk(0,10)
#print(appsDF)

#****************** Export Reports ******************
endpointsDF.to_csv('.\endpoints.csv')
allCVEDF.to_csv('.\CVEReport.csv')
appsDF.to_csv('.\Apps.csv')

#****************** Merge CVE and Apps Report on Product Name / App Name ******************
CVEAppsDF = pd.merge(allCVEDF, appsDF, left_on='productName', right_on='appName')
CVEAppsDF.to_csv('.\CVEApps.csv')
print("Open CVEApps.csv file to see CVE report with apps that have a patch")